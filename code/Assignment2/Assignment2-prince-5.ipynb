{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"tocheading\">Table of Contents</h2>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import random\n",
    "import spacy\n",
    "import csv\n",
    "import string\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Upload & Preprocessing\n",
    "The datasets provided are already tokenized. Thus, without running the data through a tokenizer, we use pretrained word embeddings (e.g. fast-Text) to embed the tokens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Vectors\n",
    "\n",
    "The web page for recommended word vector sets can be found here: https://fasttext.cc/docs/en/english-vectors.html wiki-news-300d-1M.vec from Mikolov et al (2018, Advances in Pre-Training Distributed Word Representations) 1 million word vectors trained on Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens) is used in this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', \n",
    "                  newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        ## convert all maps to lists\n",
    "        data[tokens[0]] = [*map(float, tokens[1:])]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the wiki word vectors\n",
    "fname = \"wiki-news-300d-1M.vec\"\n",
    "word_vectors = load_vectors(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vocab_tokens = [*word_vectors.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique tokens in the wiki news English vectors is 999994\n"
     ]
    }
   ],
   "source": [
    "print (\"The number of unique tokens in the wiki news English vectors is \" + str(len(all_vocab_tokens) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from Vocab Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_df = pd.DataFrame(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_df = word_vector_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_lookup = np.array(word_vector_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_vocab(table_df):\n",
    "    \n",
    "    token_array = np.array([*table_df.index])\n",
    "    num_index_array = np.array([*range(table_df.shape[0])])\n",
    "    \n",
    "    token2id = {}\n",
    "    id2token = {}\n",
    "    for i in [*range(len(token_array))]:\n",
    "        token2id[token_array[i]] = num_index_array[i]\n",
    "        id2token[num_index_array[i]] = token_array[i]\n",
    "\n",
    "    return token2id, id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2id_wiki, id2token_wiki = index_vocab(word_vector_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Check for table correctness!__\n",
    "\n",
    "Do token2id and id2token match each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93141"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2id_wiki[\"Alberto\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alberto'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2token_wiki[93141]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the table fit the initial word vector vocab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(word_vectors[\"Alberto\"] == table_lookup[93141])==True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1: SNLI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\"entailment\":1,\n",
    "             \"neutral\":0,\n",
    "             \"contradiction\":-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_train = pd.read_table(\"data/snli_train.tsv\")\n",
    "snli_val = pd.read_table(\"data/snli_val.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get tokenized training data\n",
    "snli_train[\"sentence1\"] = snli_train[\"sentence1\"].apply(lambda x: x.split(\" \"))\n",
    "snli_train[\"sentence2\"] = snli_train[\"sentence2\"].apply(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get labels\n",
    "snli_train[\"label_num\"] = snli_train[\"label\"].apply(lambda x: label_dict[x])\n",
    "snli_val[\"label_num\"] = snli_val[\"label\"].apply(lambda x: label_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get tokenized validation data\n",
    "snli_val[\"sentence1\"] = snli_val[\"sentence1\"].apply(lambda x: x.split(\" \"))\n",
    "snli_val[\"sentence2\"] = snli_val[\"sentence2\"].apply(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get label arrays\n",
    "snli_train_labels = np.array(snli_train[\"label_num\"])\n",
    "snli_val_labels = np.array(snli_val[\"label_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Three, women, on, a, stage, ,, one, wearing, ...</td>\n",
       "      <td>[There, are, two, women, standing, on, the, st...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Four, people, sit, on, a, subway, two, read, ...</td>\n",
       "      <td>[Multiple, people, are, on, a, subway, togethe...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bicycles, stationed, while, a, group, of, peo...</td>\n",
       "      <td>[People, get, together, near, a, stand, of, bi...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  [Three, women, on, a, stage, ,, one, wearing, ...   \n",
       "1  [Four, people, sit, on, a, subway, two, read, ...   \n",
       "2  [bicycles, stationed, while, a, group, of, peo...   \n",
       "\n",
       "                                           sentence2          label  label_num  \n",
       "0  [There, are, two, women, standing, on, the, st...  contradiction         -1  \n",
       "1  [Multiple, people, are, on, a, subway, togethe...     entailment          1  \n",
       "2  [People, get, together, near, a, stand, of, bi...     entailment          1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snli_val.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2: MultiNLI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_train = pd.read_table(\"data/mnli_train.tsv\")\n",
    "mnli_val = pd.read_table(\"data/mnli_val.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and now that was in fifty one that 's forty ye...</td>\n",
       "      <td>It was already a problem forty years ago but n...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jon could smell baked bread on the air and his...</td>\n",
       "      <td>Jon smelt food in the air and was hungry .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it will be like Italian basketball with the uh...</td>\n",
       "      <td>This type of Italian basketball is nothing lik...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>telephone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  and now that was in fifty one that 's forty ye...   \n",
       "1  Jon could smell baked bread on the air and his...   \n",
       "2  it will be like Italian basketball with the uh...   \n",
       "\n",
       "                                           sentence2          label      genre  \n",
       "0  It was already a problem forty years ago but n...        neutral  telephone  \n",
       "1         Jon smelt food in the air and was hungry .        neutral    fiction  \n",
       "2  This type of Italian basketball is nothing lik...  contradiction  telephone  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "telephone     4270\n",
       "slate         4026\n",
       "travel        3985\n",
       "government    3883\n",
       "fiction       3836\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_train[\"genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get tokenized training data\n",
    "mnli_train[\"sentence1\"] = mnli_train[\"sentence1\"].apply(lambda x: x.split(\" \"))\n",
    "mnli_train[\"sentence2\"] = mnli_train[\"sentence2\"].apply(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get tokenized validation data\n",
    "mnli_val[\"sentence1\"] = mnli_val[\"sentence1\"].apply(lambda x: x.split(\" \"))\n",
    "mnli_val[\"sentence2\"] = mnli_val[\"sentence2\"].apply(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get labels\n",
    "mnli_train[\"label_num\"] = mnli_train[\"label\"].apply(lambda x: label_dict[x])\n",
    "mnli_val[\"label_num\"] = mnli_val[\"label\"].apply(lambda x: label_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get train and val datasets for each __MNLI genre__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## telephone\n",
    "mnli_train_telephone = mnli_train[mnli_train[\"genre\"]==\"telephone\"]\n",
    "mnli_val_telephone = mnli_val[mnli_val[\"genre\"]==\"telephone\"]\n",
    "## slate\n",
    "mnli_train_slate = mnli_train[mnli_train[\"genre\"]==\"slate\"]\n",
    "mnli_val_slate = mnli_val[mnli_val[\"genre\"]==\"slate\"]\n",
    "## travel\n",
    "mnli_train_travel = mnli_train[mnli_train[\"genre\"]==\"travel\"]\n",
    "mnli_val_travel = mnli_val[mnli_val[\"genre\"]==\"travel\"]\n",
    "## government\n",
    "mnli_train_government = mnli_train[mnli_train[\"genre\"]==\"government\"]\n",
    "mnli_val_government = mnli_val[mnli_val[\"genre\"]==\"government\"]\n",
    "## fiction\n",
    "mnli_train_fiction = mnli_train[mnli_train[\"genre\"]==\"fiction\"]\n",
    "mnli_val_fiction = mnli_val[mnli_val[\"genre\"]==\"fiction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get label arrays for each train and val dataset\n",
    "\n",
    "## whole MNLI dataset\n",
    "mnli_train_labels = np.array(mnli_train[\"label_num\"])\n",
    "mnli_val_labels = np.array(mnli_val[\"label_num\"])\n",
    "## telephone\n",
    "mnli_train_tel_labels = np.array(mnli_train_telephone[\"label_num\"])\n",
    "mnli_val_tel_labels = np.array(mnli_val_telephone[\"label_num\"])\n",
    "## slate\n",
    "mnli_train_slate_labels = np.array(mnli_train_slate[\"label_num\"])\n",
    "mnli_val_slate_labels = np.array(mnli_val_slate[\"label_num\"])\n",
    "## travel\n",
    "mnli_train_travel_labels = np.array(mnli_train_travel[\"label_num\"])\n",
    "mnli_val_travel_labels = np.array(mnli_val_travel[\"label_num\"])\n",
    "## gov\n",
    "mnli_train_gov_labels = np.array(mnli_train_government[\"label_num\"])\n",
    "mnli_val_gov_labels = np.array(mnli_val_government[\"label_num\"])\n",
    "## fiction\n",
    "mnli_train_fiction_labels = np.array(mnli_train_fiction[\"label_num\"])\n",
    "mnli_val_fiction_labels = np.array(mnli_val_fiction[\"label_num\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## idx = token2id_wiki\n",
    "\n",
    "def token2index_dataset(tokens_data,idx_dict=None):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        ## get index list for each sentence.\n",
    "        index_list = [idx_dict[token] if token in \\\n",
    "                      idx_dict else idx_dict[\"unk\"] for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ I am getting the indices for Sentence 1 and Sentence 2 separately (not concatenating them at first from the beginning) since, in hyperparameter search I want to try more than one ways of interacting the hidden representations of the two sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get train and val indices for both datasets\n",
    "\n",
    "## SNLI\n",
    "snli_train_sentence1_indices = token2index_dataset([*snli_train[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "snli_train_sentence2_indices = token2index_dataset([*snli_train[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "snli_val_sentence1_indices = token2index_dataset([*snli_val[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "snli_val_sentence2_indices = token2index_dataset([*snli_val[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "\n",
    "## MNLI\n",
    "mnli_train_sentence1_indices = token2index_dataset([*mnli_train[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_train_sentence2_indices = token2index_dataset([*mnli_train[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_sentence1_indices = token2index_dataset([*mnli_val[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_sentence2_indices = token2index_dataset([*mnli_train[\"sentence2\"]],idx_dict=token2id_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENRES\n",
    "\n",
    "## telephone\n",
    "mnli_train_s1_tel_ix = token2index_dataset([*mnli_train_telephone[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_train_s2_tel_ix = token2index_dataset([*mnli_train_telephone[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s1_tel_ix = token2index_dataset([*mnli_val_telephone[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s2_tel_ix = token2index_dataset([*mnli_val_telephone[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "## slate\n",
    "mnli_train_s1_slate_ix = token2index_dataset([*mnli_train_slate[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_train_s2_slate_ix = token2index_dataset([*mnli_train_slate[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s1_slate_ix = token2index_dataset([*mnli_val_slate[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s2_slate_ix = token2index_dataset([*mnli_val_slate[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "## travel\n",
    "mnli_train_s1_travel_ix = token2index_dataset([*mnli_train_travel[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_train_s2_travel_ix = token2index_dataset([*mnli_train_travel[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s1_travel_ix = token2index_dataset([*mnli_val_travel[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s2_travel_ix = token2index_dataset([*mnli_val_travel[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "## gov\n",
    "mnli_train_s1_gov_ix = token2index_dataset([*mnli_train_government[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_train_s2_gov_ix = token2index_dataset([*mnli_train_government[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s1_gov_ix = token2index_dataset([*mnli_val_government[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s2_gov_ix = token2index_dataset([*mnli_val_government[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "## fiction\n",
    "mnli_train_s1_fiction_ix = token2index_dataset([*mnli_train_fiction[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_train_s2_fiction_ix = token2index_dataset([*mnli_train_fiction[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s1_fiction_ix = token2index_dataset([*mnli_val_fiction[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s2_fiction_ix = token2index_dataset([*mnli_val_fiction[\"sentence2\"]],idx_dict=token2id_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get concatenated tokens\n",
    "snli_train_concat_indices = [snli_train_sentence1_indices[i]+snli_train_sentence2_indices[i] for i in [*range(len(snli_train_sentence1_indices))]]\n",
    "snli_val_concat_indices = [snli_val_sentence1_indices[i]+snli_val_sentence2_indices[i] for i in [*range(len(snli_val_sentence1_indices))]]\n",
    "\n",
    "mnli_train_concat_indices = [mnli_train_sentence1_indices[i]+mnli_train_sentence2_indices[i] for i in [*range(len(mnli_train_sentence1_indices))]]\n",
    "mnli_val_concat_indices = [mnli_val_sentence1_indices[i]+mnli_val_sentence2_indices[i] for i in [*range(len(mnli_val_sentence1_indices))]]\n",
    "\n",
    "## GENRES\n",
    "\n",
    "## telephone\n",
    "mnli_train_tel_concat_indices = [mnli_train_s1_tel_ix[i]+mnli_train_s2_tel_ix[i] for i in [*range(len(mnli_train_s1_tel_ix))]]\n",
    "mnli_val_tel_concat_indices = [mnli_val_s1_tel_ix[i]+mnli_val_s2_tel_ix[i] for i in [*range(len(mnli_val_s1_tel_ix))]]\n",
    "## slate\n",
    "mnli_train_slate_concat_indices = [mnli_train_s1_slate_ix[i]+mnli_train_s2_slate_ix[i] for i in [*range(len(mnli_train_s2_slate_ix))]]\n",
    "mnli_val_slate_concat_indices = [mnli_val_s1_slate_ix[i]+mnli_val_s2_slate_ix[i] for i in [*range(len(mnli_val_s2_slate_ix))]]\n",
    "## travel\n",
    "mnli_train_travel_concat_indices = [mnli_train_s1_travel_ix[i]+mnli_train_s2_travel_ix[i] for i in [*range(len(mnli_train_s2_travel_ix))]]\n",
    "mnli_val_travel_concat_indices = [mnli_val_s1_travel_ix[i]+mnli_val_s2_travel_ix[i] for i in [*range(len(mnli_val_s2_travel_ix))]]\n",
    "## gov\n",
    "mnli_train_gov_concat_indices = [mnli_train_s1_gov_ix[i]+mnli_train_s2_gov_ix[i] for i in [*range(len(mnli_train_s2_gov_ix))]]\n",
    "mnli_val_gov_concat_indices = [mnli_val_s1_gov_ix[i]+mnli_val_s2_gov_ix[i] for i in [*range(len(mnli_val_s2_gov_ix))]]\n",
    "## fiction\n",
    "mnli_train_fiction_concat_indices = [mnli_train_s1_fiction_ix[i]+mnli_train_s2_fiction_ix[i] for i in [*range(len(mnli_train_s2_fiction_ix))]]\n",
    "mnli_val_fiction_concat_indices = [mnli_val_s1_fiction_ix[i]+mnli_val_s2_fiction_ix[i] for i in [*range(len(mnli_val_s2_fiction_ix))]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting training and validation set __labels__ (targets) for both datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SNLI\n",
    "snli_train_labels = np.array(snli_train[\"label_num\"])\n",
    "snli_val_labels = np.array(snli_val[\"label_num\"])\n",
    "\n",
    "## MNLI\n",
    "mnli_train_labels = np.array(mnli_train[\"label_num\"])\n",
    "mnli_val_labels = np.array(mnli_val[\"label_num\"])\n",
    "\n",
    "## GENRES\n",
    "\n",
    "## telephone\n",
    "mnli_train_tel_labels = np.array(mnli_train_telephone[\"label_num\"])\n",
    "mnli_val_tel_labels = np.array(mnli_val_telephone[\"label_num\"])\n",
    "## slate\n",
    "mnli_train_slate_labels = np.array(mnli_train_slate[\"label_num\"])\n",
    "mnli_val_slate_labels = np.array(mnli_val_slate[\"label_num\"])\n",
    "## travel\n",
    "mnli_train_travel_labels = np.array(mnli_train_travel[\"label_num\"])\n",
    "mnli_val_travel_labels = np.array(mnli_val_travel[\"label_num\"])\n",
    "## gov\n",
    "mnli_train_gov_labels = np.array(mnli_train_government[\"label_num\"])\n",
    "mnli_val_gov_labels = np.array(mnli_val_government[\"label_num\"])\n",
    "## fiction\n",
    "mnli_train_fiction_labels = np.array(mnli_train_fiction[\"label_num\"])\n",
    "mnli_val_fiction_labels = np.array(mnli_val_fiction[\"label_num\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get pretrained word embeddings from the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999994, 300)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_lookup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embed(dataset_indices=None,\n",
    "                            method=\"concat\"):\n",
    "    \n",
    "    \"\"\"Takes as input dataset indices and uses the pretrained \n",
    "    word embedding matrix to look up the vector representation for each word,\n",
    "    then interacts the two sentences according to the specified method.\n",
    "    For ex: dataset_indices = snli_train_concat_indices\n",
    "            method = 'concat' \n",
    "            \n",
    "    Returns a numpy array of embeddings\n",
    "            \n",
    "    To be used instead of nn.Embedding in the model class\"\"\"\n",
    "    \n",
    "    sentence_matrixrep = []\n",
    "    \n",
    "    for i in [*range(len(dataset_indices))]:\n",
    "        sentence_rep = [table_lookup[x] if x != \"-\" else None for x in dataset_indices[i]]\n",
    "        sentence_matrixrep.append(sentence_rep)\n",
    "            \n",
    "    embeddings = np.array([np.array(n) for n in sentence_matrixrep])\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
       "        [ 0.038 , -0.0449, -0.0897, ...,  0.0795,  0.0255, -0.027 ],\n",
       "        [-0.0433, -0.0663, -0.0548, ...,  0.0326,  0.2213,  0.0096],\n",
       "        ...,\n",
       "        [ 0.0897,  0.016 , -0.0571, ...,  0.1559, -0.0254, -0.0259],\n",
       "        [ 0.0324,  0.1127,  0.0299, ...,  0.0468,  0.1144, -0.0125],\n",
       "        [ 0.0004,  0.0032, -0.0204, ...,  0.207 ,  0.0689, -0.0467]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embed(snli_train_concat_indices[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code taken from lab3\n",
    "\n",
    "## SNLI\n",
    "MAX_SENTENCE_LENGTH = 200\n",
    "snli_train_targets = snli_train_labels\n",
    "snli_val_targets = snli_val_labels\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SNLI_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of newsgroup tokens \n",
    "        @param target_list: list of newsgroup targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx), label]\n",
    "\n",
    "def snli_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "#         data_list.append(datum[0])\n",
    "        \n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "        \n",
    "    return [torch.from_numpy(np.array(data_list)), \n",
    "            torch.LongTensor(length_list), \n",
    "            torch.LongTensor(label_list)]\n",
    "\n",
    "# create pytorch dataloader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "snli_train_dataset = SNLI_Dataset(snli_train_concat_indices,snli_train_labels)\n",
    "snli_train_loader = torch.utils.data.DataLoader(dataset=snli_train_dataset,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=snli_func,\n",
    "                                               shuffle=True)\n",
    "\n",
    "snli_val_dataset = SNLI_Dataset(snli_val_concat_indices, snli_val_labels)\n",
    "snli_val_loader = torch.utils.data.DataLoader(dataset=snli_val_dataset,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             collate_fn=snli_func,\n",
    "                                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 76579, 816560, 683763,  ...,      0,      0,      0],\n",
       "         [662682, 937843, 802154,  ...,      0,      0,      0],\n",
       "         [ 76579, 980614, 773898,  ...,      0,      0,      0],\n",
       "         ...,\n",
       "         [ 76579, 822411, 794698,  ...,      0,      0,      0],\n",
       "         [ 76579, 691841, 739190,  ...,      0,      0,      0],\n",
       "         [ 76579, 822411, 672856,  ...,      0,      0,      0]]),\n",
       " tensor([23, 28, 27, 27, 26, 22, 27, 22, 19, 23, 16, 21, 18, 21, 13, 63, 14, 33,\n",
       "         21, 18, 18, 12, 26, 20, 17, 21, 30, 30, 16, 36, 18, 17]),\n",
       " tensor([ 1, -1,  1,  0,  0,  1, -1,  0, -1, -1, -1, -1, -1,  0, -1, -1,  1,  0,\n",
       "          0, -1,  1,  1,  1,  0, -1,  0,  1,  0, -1,  0, -1,  0])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*snli_val_loader][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "## code taken from lab3\n",
    "## mnli\n",
    "MAX_SENTENCE_LENGTH = 200\n",
    "mnli_train_targets = mnli_train_labels\n",
    "mnli_val_targets = mnli_val_labels\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MNLI_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of newsgroup tokens \n",
    "        @param target_list: list of newsgroup targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx), label]\n",
    "\n",
    "def mnli_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "        \n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "            \n",
    "        data_list.append(padded_vec)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return [torch.from_numpy(np.array(data_list)), \n",
    "            torch.LongTensor(length_list), \n",
    "            torch.LongTensor(label_list)]\n",
    "\n",
    "# create pytorch dataloader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "mnli_train_dataset = MNLI_Dataset(mnli_train_concat_indices,mnli_train_labels)\n",
    "mnli_train_loader = torch.utils.data.DataLoader(dataset=mnli_train_dataset,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=mnli_func,\n",
    "                                               shuffle=True)\n",
    "\n",
    "mnli_val_dataset = MNLI_Dataset(mnli_val_concat_indices, mnli_val_labels)\n",
    "mnli_val_loader = torch.utils.data.DataLoader(dataset=mnli_val_dataset,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             collate_fn=mnli_func,\n",
    "                                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[961193, 578022,   2924,  ...,      0,      0,      0],\n",
       "         [187482, 944934, 512775,  ...,      0,      0,      0],\n",
       "         [255405, 898138,   2924,  ...,      0,      0,      0],\n",
       "         ...,\n",
       "         [562796, 723455, 704565,  ...,      0,      0,      0],\n",
       "         [ 88713, 662682, 868293,  ...,      0,      0,      0],\n",
       "         [190300, 853891, 316602,  ...,      0,      0,      0]]),\n",
       " tensor([ 30,  12,  32,  28,  48,  15,  16,  50, 132,  23,  23,  54,  44,  24,\n",
       "          36,  82,  20,  49,  28,  28,  44,  16,  23,  21,  23,  41,  21,  19,\n",
       "          32,  34,  30,  36]),\n",
       " tensor([-1, -1, -1,  0,  1,  1,  1,  0, -1,  0, -1,  1, -1,  0,  1,  0,  0,  0,\n",
       "          1, -1, -1,  0,  1, -1, -1,  0,  1,  0, -1, -1,  1, -1])]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*mnli_train_loader][29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embed(dataset_indices=None,\n",
    "                            method=\"concat\"):\n",
    "    \n",
    "    \"\"\"Takes as input dataset indices and uses the pretrained \n",
    "    word embedding matrix to look up the vector representation for each word,\n",
    "    then interacts the two sentences according to the specified method.\n",
    "    For ex: dataset_indices = snli_train_concat_indices\n",
    "            method = 'concat' \n",
    "            \n",
    "    Returns a numpy array of embeddings\n",
    "            \n",
    "    To be used instead of nn.Embedding in the model class\"\"\"\n",
    "    \n",
    "    sentence_matrixrep = []\n",
    "    \n",
    "    for i in [*range(len(dataset_indices))]:\n",
    "        sentence_rep = [table_lookup[x] if x != \"-\" else None for x in dataset_indices[i]]\n",
    "        sentence_matrixrep.append(sentence_rep)\n",
    "            \n",
    "    embeddings = np.array([np.array(n) for n in sentence_matrixrep])\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Model\n",
    "\n",
    "The model is trained on SNLI training set. The best model is chosen using SNLI validation set, then the best model is evaluated on each genre in MultiNLI validation set. \n",
    "\n",
    "We will use an encoder (either a CNN or an RNN) to map each string of text (hypothesis and premise) to a fixed-dimension vector representation. We will interact the two hidden representations and output a 3-class soft- max. (To keep things simple, we will simply concatenate the two repre- sentations, and feed them through a network of 2 fully-connected layers.) For the encoder, we want the following:\n",
    "\n",
    "### Part 2.1: CNN\n",
    "For the CNN, a 2-layer 1-D convolutional network with ReLU activations will suffice. We can perform a max-pool at the end to compress the hidden representation into a single vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # FloatTensor containing pretrained weights\n",
    "# >> weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])\n",
    "# >> embedding = nn.Embedding.from_pretrained(weight)\n",
    "# >> # Get embeddings for index 1\n",
    "# >> input = torch.LongTensor([1])\n",
    "# >> embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = [*snli_train_dataset]\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,emb_size,\n",
    "                 hidden_size, \n",
    "                 num_layers, \n",
    "                 num_classes,\n",
    "                vocab_size):\n",
    "\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "#         self.emb_size = emb_size\n",
    "        ## use pretrained wiki embeddings\n",
    "        wiki_embed_table = torch.tensor(table_lookup)\n",
    "        embedding = nn.Embedding.from_pretrained(wiki_embed_table)\n",
    "        self.embedding = embedding\n",
    "    \n",
    "        self.conv1 = nn.Conv1d(emb_size, hidden_size, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        batch_size, seq_len = x.size()\n",
    "        ## initialize batch embeddings\n",
    "        embeds = []\n",
    "        ## get embeddings for each sentence couple in batch\n",
    "        ## exclude zero-pads at the end, if you don't slice by length \n",
    "        ## the model will get table_lookup[0] for 0-pads\n",
    "        MAX_SENTENCE_LENGTH = 200\n",
    "        for arr in [*range(len(x))]: \n",
    "            input = torch.LongTensor(x[arr][:int(lengths[arr])])\n",
    "#             embed = embedding(torch.LongTensor(input))\n",
    "            embed = embedding(input)\n",
    "            ## pad again\n",
    "            length_to_pad = MAX_SENTENCE_LENGTH - embed.size()[0]\n",
    "            embed = np.vstack((embed.numpy(),np.zeros((length_to_pad,300))))\n",
    "            embeds.append(embed)\n",
    "            \n",
    "#         print (\"embeds-\"+str(embeds))\n",
    "        embeds = torch.FloatTensor(embeds)\n",
    "#         print (embeds.size()) # 32\n",
    "#         hidden = self.conv1(embed.transpose(1,-2)).transpose(1,-2)\n",
    "        hidden = self.conv1(embeds)\n",
    "\n",
    "\n",
    "        print (\"hidden = \"+str(hidden))\n",
    "        hidden = F.relu(hidden.contiguous().view(-1, hidden.size(-1))).view(batch_size, seq_len, hidden.size(-1))\n",
    "\n",
    "        hidden = self.conv2(hidden.transpose(-2,1)).transpose(-2,1)\n",
    "        hidden = F.relu(hidden.contiguous().view(-1, hidden.size(-1))).view(batch_size, seq_len, hidden.size(-1))\n",
    "\n",
    "        hidden = torch.sum(hidden, dim=1)\n",
    "        logits = self.linear(hidden)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(emb_size=300, hidden_size=200, num_layers=2, num_classes=3, vocab_size=wiki_embed_table.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-4\n",
    "num_epochs = 10 # number epoch to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeds-[array([[-0.038 , -0.0278, -0.0227, ..., -0.1878,  0.3144,  0.1036],\n",
      "       [-0.0965, -0.0777,  0.0006, ...,  0.0649,  0.1015, -0.0266],\n",
      "       [-0.007 ,  0.0228, -0.1499, ...,  0.1013, -0.0968,  0.0194],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.038 , -0.0278, -0.0227, ..., -0.1878,  0.3144,  0.1036],\n",
      "       [-0.0126,  0.0669, -0.1186, ...,  0.1152,  0.0349,  0.0512],\n",
      "       [-0.023 ,  0.0005, -0.042 , ...,  0.1031, -0.0753,  0.0264],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
      "       [ 0.0751, -0.0591, -0.0102, ...,  0.0501,  0.133 ,  0.0352],\n",
      "       [ 0.0156,  0.0752, -0.078 , ...,  0.0882, -0.0882, -0.0096],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
      "       [ 0.1035,  0.1325, -0.0601, ...,  0.0488, -0.0858, -0.024 ],\n",
      "       [ 0.0081, -0.0587, -0.0963, ...,  0.0022,  0.0913,  0.0065],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[ 0.0797, -0.0294,  0.0033, ...,  0.1372,  0.0669, -0.0084],\n",
      "       [-0.2212, -0.0308, -0.0578, ...,  0.0397,  0.2317, -0.0511],\n",
      "       [-0.0234, -0.0268, -0.0838, ...,  0.1048, -0.0148, -0.0452],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
      "       [ 0.1484,  0.031 ,  0.048 , ...,  0.0317, -0.0849,  0.0696],\n",
      "       [-0.0063, -0.0253, -0.0338, ...,  0.1155,  0.0073,  0.0168],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
      "       [-0.0183, -0.082 , -0.1086, ...,  0.0905,  0.0891,  0.0057],\n",
      "       [ 0.0177, -0.0273, -0.0135, ...,  0.1877,  0.0338, -0.0671],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.038 , -0.0278, -0.0227, ..., -0.1878,  0.3144,  0.1036],\n",
      "       [ 0.0027, -0.0543, -0.1326, ...,  0.1568,  0.1094, -0.0207],\n",
      "       [ 0.1073,  0.0089,  0.0006, ...,  0.005 ,  0.1173, -0.04  ],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
      "       [-0.1559, -0.036 ,  0.1424, ..., -0.0997,  0.3089,  0.0083],\n",
      "       [-0.1434, -0.0058,  0.0397, ..., -0.1034,  0.3015, -0.0936],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
      "       [ 0.0751, -0.0591, -0.0102, ...,  0.0501,  0.133 ,  0.0352],\n",
      "       [-0.0234, -0.0268, -0.0838, ...,  0.1048, -0.0148, -0.0452],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.038 , -0.0278, -0.0227, ..., -0.1878,  0.3144,  0.1036],\n",
      "       [ 0.086 , -0.125 , -0.0343, ...,  0.0198,  0.0013,  0.0524],\n",
      "       [ 0.0479, -0.0984,  0.0082, ...,  0.1425, -0.1341,  0.0564],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
      "       [-0.0697, -0.0505, -0.1169, ...,  0.0794, -0.0229,  0.0536],\n",
      "       [-0.0234, -0.0268, -0.0838, ...,  0.1048, -0.0148, -0.0452],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
      "       [-0.0183, -0.082 , -0.1086, ...,  0.0905,  0.0891,  0.0057],\n",
      "       [ 0.0156,  0.0752, -0.078 , ...,  0.0882, -0.0882, -0.0096],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
      "       [ 0.0397,  0.2867,  0.0958, ..., -0.06  ,  0.0257,  0.0036],\n",
      "       [-0.0234, -0.0268, -0.0838, ...,  0.1048, -0.0148, -0.0452],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
      "       [-0.0183, -0.082 , -0.1086, ...,  0.0905,  0.0891,  0.0057],\n",
      "       [-0.0234, -0.0268, -0.0838, ...,  0.1048, -0.0148, -0.0452],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
      "       [ 0.0751, -0.0591, -0.0102, ...,  0.0501,  0.133 ,  0.0352],\n",
      "       [ 0.0156,  0.0752, -0.078 , ...,  0.0882, -0.0882, -0.0096],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[ 0.0134,  0.0171, -0.0344, ...,  0.1915,  0.2418,  0.0458],\n",
      "       [ 0.086 , -0.125 , -0.0343, ...,  0.0198,  0.0013,  0.0524],\n",
      "       [-0.0234, -0.0268, -0.0838, ...,  0.1048, -0.0148, -0.0452],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[ 0.0047,  0.0223, -0.0087, ...,  0.1479,  0.1324, -0.0318],\n",
      "       [-0.0215, -0.228 ,  0.056 , ...,  0.2047, -0.0881,  0.0872],\n",
      "       [-0.2212, -0.0308, -0.0578, ...,  0.0397,  0.2317, -0.0511],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
      "       [ 0.038 , -0.0449, -0.0897, ...,  0.0795,  0.0255, -0.027 ],\n",
      "       [ 0.0751, -0.0591, -0.0102, ...,  0.0501,  0.133 ,  0.0352],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[ 0.0017, -0.0849,  0.0501, ..., -0.174 ,  0.2415,  0.0484],\n",
      "       [-0.0234, -0.0268, -0.0838, ...,  0.1048, -0.0148, -0.0452],\n",
      "       [ 0.028 , -0.0189,  0.0357, ...,  0.0225,  0.1797, -0.015 ],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
      "       [-0.0183, -0.082 , -0.1086, ...,  0.0905,  0.0891,  0.0057],\n",
      "       [-0.0234, -0.0268, -0.0838, ...,  0.1048, -0.0148, -0.0452],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0153, -0.0445,  0.1359, ...,  0.0008,  0.0004,  0.0365],\n",
      "       [ 0.0754, -0.0416, -0.0213, ...,  0.0694, -0.0035, -0.169 ],\n",
      "       [ 0.0751, -0.0591, -0.0102, ...,  0.0501,  0.133 ,  0.0352],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
      "       [ 0.0051, -0.0042,  0.0308, ...,  0.0831,  0.2989,  0.1118],\n",
      "       [-0.0868,  0.0528,  0.125 , ...,  0.2276, -0.0748,  0.0179],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
      "       [ 0.0751, -0.0591, -0.0102, ...,  0.0501,  0.133 ,  0.0352],\n",
      "       [ 0.0177, -0.0273, -0.0135, ...,  0.1877,  0.0338, -0.0671],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[ 0.0631, -0.0572, -0.1043, ..., -0.1086,  0.2419,  0.1763],\n",
      "       [ 0.1093, -0.0421, -0.0742, ..., -0.0655,  0.0323,  0.0204],\n",
      "       [ 0.018 , -0.0244, -0.0906, ...,  0.0612, -0.0505, -0.0794],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[ 0.0382, -0.0135,  0.0388, ...,  0.0295,  0.1484,  0.0616],\n",
      "       [ 0.0104,  0.1101, -0.0982, ...,  0.1598, -0.0329,  0.0798],\n",
      "       [-0.007 ,  0.0228, -0.1499, ...,  0.1013, -0.0968,  0.0194],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0143,  0.0212, -0.0079, ..., -0.0535,  0.0626,  0.0905],\n",
      "       [-0.007 ,  0.0228, -0.1499, ...,  0.1013, -0.0968,  0.0194],\n",
      "       [-0.1206,  0.0069, -0.1585, ...,  0.1424, -0.1512, -0.1017],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[ 0.0631, -0.0572, -0.1043, ..., -0.1086,  0.2419,  0.1763],\n",
      "       [ 0.0965, -0.0063, -0.0171, ...,  0.152 , -0.0753,  0.0948],\n",
      "       [-0.0078,  0.0671, -0.0253, ...,  0.1954,  0.082 , -0.0966],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
      "       [-0.0302,  0.0449, -0.0881, ..., -0.1783, -0.0169, -0.0382],\n",
      "       [-0.0183, -0.082 , -0.1086, ...,  0.0905,  0.0891,  0.0057],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.0595, -0.0428,  0.06  , ...,  0.0235,  0.215 ,  0.0581],\n",
      "       [ 0.038 , -0.0449, -0.0897, ...,  0.0795,  0.0255, -0.027 ],\n",
      "       [ 0.0724, -0.0468,  0.0221, ..., -0.1035,  0.1283,  0.1294],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[ 0.0373,  0.0305, -0.0496, ..., -0.1828,  0.1415, -0.0408],\n",
      "       [ 0.086 , -0.125 , -0.0343, ...,  0.0198,  0.0013,  0.0524],\n",
      "       [-0.0314,  0.0149, -0.0205, ...,  0.098 ,  0.0893,  0.0148],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]]), array([[-0.038 , -0.0278, -0.0227, ..., -0.1878,  0.3144,  0.1036],\n",
      "       [ 0.0312, -0.0823, -0.0251, ...,  0.0991,  0.1129,  0.0351],\n",
      "       [-0.0234, -0.0268, -0.0838, ...,  0.1048, -0.0148, -0.0452],\n",
      "       ...,\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],\n",
      "       [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]])]\n",
      "torch.Size([32, 200, 300])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [200, 300, 3], expected input[32, 200, 300] to have 300 channels, but got 200 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-615-9897a04081bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-cpu/py3.6.3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-611-72b948240112>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, lengths)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#         hidden = self.conv1(embed.transpose(1,-2)).transpose(1,-2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-cpu/py3.6.3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-cpu/py3.6.3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 176\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [200, 300, 3], expected input[32, 200, 300] to have 300 channels, but got 200 channels instead"
     ]
    }
   ],
   "source": [
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, lengths_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, lengths_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n",
    "total_step = len(snli_train_loader)\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, lengths, labels) in enumerate(snli_train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(data, lengths)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # validate every 100 iterations\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            # validate\n",
    "            val_acc = test_model(snli_val_loader, model)\n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format(\n",
    "                       epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Search\n",
    "\n",
    "The hyperparameters included in the hyperparameter search space are;\n",
    "\n",
    "- The size of the hidden dimension of the CNN and RNN,\n",
    "- The kernel size of the CNN,\n",
    "- Experiment with different ways of interacting the two encoded sentences (concatenation, element-wise multiplication, outer multiplication etc)\n",
    "- Regularization (e.g. weight decay, dropout).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.220e-02, -4.900e-03, -1.430e-02, -1.240e-02,  2.240e-02,\n",
       "        2.650e-02,  3.730e-02, -2.200e-03,  1.800e-03, -5.170e-02,\n",
       "       -1.330e-02,  1.240e-02, -1.140e-02, -8.270e-02,  4.040e-02,\n",
       "        2.300e-02,  1.800e-02, -1.860e-02,  6.670e-02,  3.400e-03,\n",
       "       -5.980e-02, -1.340e-02, -4.430e-02, -1.070e-01, -1.950e-02,\n",
       "       -3.540e-02,  5.200e-03,  6.180e-02,  2.080e-02, -9.700e-02,\n",
       "       -2.410e-02,  1.500e-03, -5.690e-02, -2.290e-02, -2.210e-02,\n",
       "       -2.570e-02, -2.400e-02, -7.340e-02,  3.800e-02,  2.900e-02,\n",
       "        2.990e-02,  1.250e-02, -4.870e-02,  1.770e-02,  5.840e-02,\n",
       "       -4.600e-02, -2.480e-02, -1.300e-02, -2.020e-02,  2.240e-02,\n",
       "       -4.240e-02, -3.190e-02, -8.868e-01,  1.100e-03, -4.740e-02,\n",
       "        7.310e-02, -2.340e-02, -7.280e-02, -3.210e-02,  1.690e-02,\n",
       "       -4.500e-03,  4.000e-04, -2.086e-01,  1.090e-02,  1.060e-02,\n",
       "       -1.980e-02, -1.280e-02, -1.250e-02, -1.310e-02,  3.030e-02,\n",
       "       -4.600e-02, -6.100e-03,  3.830e-02, -2.110e-02,  5.500e-03,\n",
       "       -3.470e-02,  5.500e-03, -1.880e-02, -1.410e-02, -4.410e-02,\n",
       "        1.850e-02,  8.060e-02,  1.910e-02,  5.000e-02,  3.930e-02,\n",
       "        1.630e-02, -1.051e-01,  5.610e-02,  1.080e-02,  1.140e-02,\n",
       "        1.660e-02,  3.450e-02,  2.690e-02,  2.063e-01, -1.290e-02,\n",
       "       -5.860e-02,  1.680e-02,  7.900e-03, -1.150e-02,  2.130e-02,\n",
       "        5.940e-02, -1.177e-01,  1.310e-02, -2.960e-02, -3.170e-02,\n",
       "       -1.650e-02,  4.900e-03,  3.620e-02, -7.300e-02,  2.200e-03,\n",
       "       -2.140e-02, -3.980e-02, -6.110e-02,  2.180e-02,  3.020e-02,\n",
       "        6.690e-02,  4.920e-02, -9.000e-03,  8.900e-03, -2.620e-02,\n",
       "        3.310e-02,  1.180e-02, -1.370e-01, -1.460e-02,  3.830e-02,\n",
       "       -3.330e-02, -6.000e-03, -3.580e-02, -6.680e-02,  2.010e-02,\n",
       "       -6.240e-02, -7.540e-02,  1.238e-01, -6.700e-03, -6.000e-04,\n",
       "        3.780e-02,  1.820e-02,  2.700e-03, -1.420e-01,  9.800e-03,\n",
       "       -6.200e-03,  7.430e-02,  1.160e-02, -5.560e-02, -3.500e-03,\n",
       "       -3.620e-02, -4.420e-02, -8.100e-03, -2.930e-02,  5.190e-02,\n",
       "       -1.244e-01, -2.900e-02, -5.240e-02, -2.030e-02, -2.200e-02,\n",
       "       -3.770e-02,  7.700e-03, -5.190e-02,  3.670e-02, -1.610e-02,\n",
       "        2.410e-02,  4.510e-02, -6.400e-03,  2.062e-01, -8.800e-03,\n",
       "        5.200e-02, -7.350e-02, -4.860e-02, -1.370e-02, -6.560e-02,\n",
       "        5.200e-03,  6.610e-02,  3.180e-02, -1.038e-01, -1.044e-01,\n",
       "        9.670e-02, -4.610e-02,  4.270e-02,  4.090e-02, -5.600e-03,\n",
       "       -9.080e-02,  2.770e-02,  4.820e-02,  2.610e-02, -2.390e-02,\n",
       "        3.580e-02,  1.510e-02,  1.317e-01,  1.700e-02, -6.290e-02,\n",
       "       -5.200e-03,  9.890e-02, -6.100e-03, -3.550e-02, -1.170e-02,\n",
       "       -9.860e-02, -3.210e-02, -7.800e-03, -9.440e-02, -4.330e-02,\n",
       "       -6.300e-03,  9.600e-03, -4.000e-03, -6.800e-03, -4.840e-02,\n",
       "       -1.240e-02,  3.600e-02,  1.104e-01, -2.170e-02, -2.600e-02,\n",
       "       -9.440e-02, -5.500e-03, -1.370e-02, -4.560e-02,  6.540e-02,\n",
       "        5.530e-02,  1.581e-01,  1.940e-02,  6.590e-02,  2.150e-02,\n",
       "       -1.350e-02,  1.500e-02, -1.140e-02, -4.640e-02, -1.144e-01,\n",
       "       -3.010e-02, -3.000e-02, -7.190e-02,  2.200e-03,  6.980e-02,\n",
       "       -1.490e-02, -3.900e-02, -6.980e-02, -3.620e-02,  4.110e-02,\n",
       "       -7.930e-02,  2.160e-02,  3.930e-02,  9.330e-02, -1.261e-01,\n",
       "        8.570e-02, -3.600e-03, -7.610e-02,  1.430e-02,  4.480e-02,\n",
       "        2.940e-02,  3.230e-02, -2.320e-02,  3.590e-02, -9.890e-02,\n",
       "        1.630e-02, -1.027e-01,  1.475e-01, -9.300e-03, -3.610e-02,\n",
       "       -4.310e-02, -2.420e-02, -3.860e-02, -3.310e-02, -5.630e-02,\n",
       "        7.130e-02,  4.400e-03,  2.920e-02, -9.900e-03, -2.202e-01,\n",
       "        2.740e-02,  1.190e-02,  2.410e-02,  9.030e-02, -2.990e-02,\n",
       "       -6.420e-02, -2.070e-02, -2.360e-02,  1.490e-02,  5.120e-02,\n",
       "       -2.520e-02, -9.600e-03,  1.610e-02, -3.600e-03,  5.300e-02,\n",
       "       -7.720e-02,  2.100e-03, -3.660e-02, -4.590e-02,  3.180e-02,\n",
       "        4.600e-02, -3.080e-02,  1.420e-02,  1.166e-01, -1.060e-02,\n",
       "       -3.070e-02,  1.750e-02,  7.140e-02,  3.910e-02, -1.520e-02,\n",
       "       -7.700e-03,  1.113e-01,  2.640e-02, -2.290e-02,  3.200e-03])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_lookup[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2 RNN\n",
    "For the RNN, a single-layer, bi-directional GRU will suffice. We can take the last hidden state as the encoder output. (In the case of bi-directional, the last of each direction, although PyTorch takes care of this.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Search\n",
    "\n",
    "The hyperparameters included in the hyperparameter search space are;\n",
    "\n",
    "- The size of the hidden dimension of the CNN and RNN,\n",
    "- Experiment with different ways of interacting the two encoded sentences (concatenation, element-wise multiplication, outer multiplication etc)\n",
    "- Regularization (e.g. weight decay, dropout)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
