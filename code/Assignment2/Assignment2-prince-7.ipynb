{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"tocheading\">Table of Contents</h2>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import random\n",
    "import spacy\n",
    "import csv\n",
    "import string\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Upload & Preprocessing\n",
    "The datasets provided are already tokenized. Thus, without running the data through a tokenizer, we use pretrained word embeddings (e.g. fast-Text) to embed the tokens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Vectors\n",
    "\n",
    "The web page for recommended word vector sets can be found here: https://fasttext.cc/docs/en/english-vectors.html wiki-news-300d-1M.vec from Mikolov et al (2018, Advances in Pre-Training Distributed Word Representations) 1 million word vectors trained on Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens) is used in this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', \n",
    "                  newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        ## convert all maps to lists\n",
    "        data[tokens[0]] = [*map(float, tokens[1:])]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the wiki word vectors\n",
    "fname = \"wiki-news-300d-1M.vec\"\n",
    "word_vectors = load_vectors(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vocab_tokens = [*word_vectors.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique tokens in the wiki news English vectors is 999994\n"
     ]
    }
   ],
   "source": [
    "print (\"The number of unique tokens in the wiki news English vectors is \" + str(len(all_vocab_tokens) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from Vocab Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_df = pd.DataFrame(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_df = word_vector_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_lookup = np.array(word_vector_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_vocab(table_df):\n",
    "    \n",
    "    token_array = np.array([*table_df.index])\n",
    "    num_index_array = np.array([*range(table_df.shape[0])])\n",
    "    \n",
    "    token2id = {}\n",
    "    id2token = {}\n",
    "    for i in [*range(len(token_array))]:\n",
    "        token2id[token_array[i]] = num_index_array[i]\n",
    "        id2token[num_index_array[i]] = token_array[i]\n",
    "\n",
    "    return token2id, id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2id_wiki, id2token_wiki = index_vocab(word_vector_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Check for table correctness!__\n",
    "\n",
    "Do token2id and id2token match each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93141"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2id_wiki[\"Alberto\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alberto'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2token_wiki[93141]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the table fit the initial word vector vocab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(word_vectors[\"Alberto\"] == table_lookup[93141])==True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1: SNLI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\"entailment\":0,\n",
    "             \"neutral\":1,\n",
    "             \"contradiction\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_train = pd.read_table(\"data/snli_train.tsv\")\n",
    "snli_val = pd.read_table(\"data/snli_val.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get tokenized training data\n",
    "snli_train[\"sentence1\"] = snli_train[\"sentence1\"].apply(lambda x: x.split(\" \"))\n",
    "snli_train[\"sentence2\"] = snli_train[\"sentence2\"].apply(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get labels\n",
    "snli_train[\"label_num\"] = snli_train[\"label\"].apply(lambda x: label_dict[x])\n",
    "snli_val[\"label_num\"] = snli_val[\"label\"].apply(lambda x: label_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get tokenized validation data\n",
    "snli_val[\"sentence1\"] = snli_val[\"sentence1\"].apply(lambda x: x.split(\" \"))\n",
    "snli_val[\"sentence2\"] = snli_val[\"sentence2\"].apply(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get label arrays\n",
    "snli_train_labels = np.array(snli_train[\"label_num\"])\n",
    "snli_val_labels = np.array(snli_val[\"label_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Three, women, on, a, stage, ,, one, wearing, ...</td>\n",
       "      <td>[There, are, two, women, standing, on, the, st...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Four, people, sit, on, a, subway, two, read, ...</td>\n",
       "      <td>[Multiple, people, are, on, a, subway, togethe...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bicycles, stationed, while, a, group, of, peo...</td>\n",
       "      <td>[People, get, together, near, a, stand, of, bi...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  [Three, women, on, a, stage, ,, one, wearing, ...   \n",
       "1  [Four, people, sit, on, a, subway, two, read, ...   \n",
       "2  [bicycles, stationed, while, a, group, of, peo...   \n",
       "\n",
       "                                           sentence2          label  label_num  \n",
       "0  [There, are, two, women, standing, on, the, st...  contradiction          2  \n",
       "1  [Multiple, people, are, on, a, subway, togethe...     entailment          0  \n",
       "2  [People, get, together, near, a, stand, of, bi...     entailment          0  "
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snli_val.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2: MultiNLI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_train = pd.read_table(\"data/mnli_train.tsv\")\n",
    "mnli_val = pd.read_table(\"data/mnli_val.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and now that was in fifty one that 's forty ye...</td>\n",
       "      <td>It was already a problem forty years ago but n...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jon could smell baked bread on the air and his...</td>\n",
       "      <td>Jon smelt food in the air and was hungry .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it will be like Italian basketball with the uh...</td>\n",
       "      <td>This type of Italian basketball is nothing lik...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>telephone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  and now that was in fifty one that 's forty ye...   \n",
       "1  Jon could smell baked bread on the air and his...   \n",
       "2  it will be like Italian basketball with the uh...   \n",
       "\n",
       "                                           sentence2          label      genre  \n",
       "0  It was already a problem forty years ago but n...        neutral  telephone  \n",
       "1         Jon smelt food in the air and was hungry .        neutral    fiction  \n",
       "2  This type of Italian basketball is nothing lik...  contradiction  telephone  "
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "telephone     4270\n",
       "slate         4026\n",
       "travel        3985\n",
       "government    3883\n",
       "fiction       3836\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli_train[\"genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get tokenized training data\n",
    "mnli_train[\"sentence1\"] = mnli_train[\"sentence1\"].apply(lambda x: x.split(\" \"))\n",
    "mnli_train[\"sentence2\"] = mnli_train[\"sentence2\"].apply(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get tokenized validation data\n",
    "mnli_val[\"sentence1\"] = mnli_val[\"sentence1\"].apply(lambda x: x.split(\" \"))\n",
    "mnli_val[\"sentence2\"] = mnli_val[\"sentence2\"].apply(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get labels\n",
    "mnli_train[\"label_num\"] = mnli_train[\"label\"].apply(lambda x: label_dict[x])\n",
    "mnli_val[\"label_num\"] = mnli_val[\"label\"].apply(lambda x: label_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get train and val datasets for each __MNLI genre__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "## telephone\n",
    "mnli_train_telephone = mnli_train[mnli_train[\"genre\"]==\"telephone\"]\n",
    "mnli_val_telephone = mnli_val[mnli_val[\"genre\"]==\"telephone\"]\n",
    "## slate\n",
    "mnli_train_slate = mnli_train[mnli_train[\"genre\"]==\"slate\"]\n",
    "mnli_val_slate = mnli_val[mnli_val[\"genre\"]==\"slate\"]\n",
    "## travel\n",
    "mnli_train_travel = mnli_train[mnli_train[\"genre\"]==\"travel\"]\n",
    "mnli_val_travel = mnli_val[mnli_val[\"genre\"]==\"travel\"]\n",
    "## government\n",
    "mnli_train_government = mnli_train[mnli_train[\"genre\"]==\"government\"]\n",
    "mnli_val_government = mnli_val[mnli_val[\"genre\"]==\"government\"]\n",
    "## fiction\n",
    "mnli_train_fiction = mnli_train[mnli_train[\"genre\"]==\"fiction\"]\n",
    "mnli_val_fiction = mnli_val[mnli_val[\"genre\"]==\"fiction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get label arrays for each train and val dataset\n",
    "\n",
    "## whole MNLI dataset\n",
    "mnli_train_labels = np.array(pd.get_dummies(np.array(mnli_train[\"label_num\"])))\n",
    "mnli_val_labels = np.array(pd.get_dummies(np.array(mnli_val[\"label_num\"])))\n",
    "## telephone\n",
    "mnli_train_tel_labels = np.array(pd.get_dummies(np.array(mnli_train_telephone[\"label_num\"])))\n",
    "mnli_val_tel_labels = np.array(pd.get_dummies(np.array(mnli_val_telephone[\"label_num\"])))\n",
    "## slate\n",
    "mnli_train_slate_labels = np.array(pd.get_dummies(np.array(mnli_train_slate[\"label_num\"])))\n",
    "mnli_val_slate_labels = np.array(pd.get_dummies(np.array(mnli_val_slate[\"label_num\"])))\n",
    "## travel\n",
    "mnli_train_travel_labels = np.array(pd.get_dummies(np.array(mnli_train_travel[\"label_num\"])))\n",
    "mnli_val_travel_labels = np.array(mnli_val_travel[\"label_num\"])\n",
    "## gov\n",
    "mnli_train_gov_labels = np.array(pd.get_dummies(np.array(mnli_train_government[\"label_num\"])))\n",
    "mnli_val_gov_labels = np.array(pd.get_dummies(np.array(mnli_val_government[\"label_num\"])))\n",
    "## fiction\n",
    "mnli_train_fiction_labels = np.array(pd.get_dummies(np.array(mnli_train_fiction[\"label_num\"])))\n",
    "mnli_val_fiction_labels = np.array(pd.get_dummies(np.array(mnli_val_fiction[\"label_num\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "## idx = token2id_wiki\n",
    "\n",
    "def token2index_dataset(tokens_data,idx_dict=None):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        ## get index list for each sentence.\n",
    "        index_list = [idx_dict[token] if token in \\\n",
    "                      idx_dict else idx_dict[\"unk\"] for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ I am getting the indices for Sentence 1 and Sentence 2 separately (not concatenating them at first from the beginning) since, in hyperparameter search I want to try more than one ways of interacting the hidden representations of the two sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get train and val indices for both datasets\n",
    "\n",
    "## SNLI\n",
    "snli_train_sentence1_indices = token2index_dataset([*snli_train[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "snli_train_sentence2_indices = token2index_dataset([*snli_train[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "snli_val_sentence1_indices = token2index_dataset([*snli_val[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "snli_val_sentence2_indices = token2index_dataset([*snli_val[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "\n",
    "## MNLI\n",
    "mnli_train_sentence1_indices = token2index_dataset([*mnli_train[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_train_sentence2_indices = token2index_dataset([*mnli_train[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_sentence1_indices = token2index_dataset([*mnli_val[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_sentence2_indices = token2index_dataset([*mnli_val[\"sentence2\"]],idx_dict=token2id_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENRES\n",
    "\n",
    "## telephone\n",
    "mnli_train_s1_tel_ix = token2index_dataset([*mnli_train_telephone[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_train_s2_tel_ix = token2index_dataset([*mnli_train_telephone[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s1_tel_ix = token2index_dataset([*mnli_val_telephone[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s2_tel_ix = token2index_dataset([*mnli_val_telephone[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "## slate\n",
    "mnli_train_s1_slate_ix = token2index_dataset([*mnli_train_slate[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_train_s2_slate_ix = token2index_dataset([*mnli_train_slate[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s1_slate_ix = token2index_dataset([*mnli_val_slate[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s2_slate_ix = token2index_dataset([*mnli_val_slate[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "## travel\n",
    "mnli_train_s1_travel_ix = token2index_dataset([*mnli_train_travel[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_train_s2_travel_ix = token2index_dataset([*mnli_train_travel[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s1_travel_ix = token2index_dataset([*mnli_val_travel[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s2_travel_ix = token2index_dataset([*mnli_val_travel[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "## gov\n",
    "mnli_train_s1_gov_ix = token2index_dataset([*mnli_train_government[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_train_s2_gov_ix = token2index_dataset([*mnli_train_government[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s1_gov_ix = token2index_dataset([*mnli_val_government[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s2_gov_ix = token2index_dataset([*mnli_val_government[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "## fiction\n",
    "mnli_train_s1_fiction_ix = token2index_dataset([*mnli_train_fiction[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_train_s2_fiction_ix = token2index_dataset([*mnli_train_fiction[\"sentence2\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s1_fiction_ix = token2index_dataset([*mnli_val_fiction[\"sentence1\"]],idx_dict=token2id_wiki)\n",
    "mnli_val_s2_fiction_ix = token2index_dataset([*mnli_val_fiction[\"sentence2\"]],idx_dict=token2id_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## get concatenated tokens\n",
    "# snli_train_concat_indices = [snli_train_sentence1_indices[i]+snli_train_sentence2_indices[i] for i in [*range(len(snli_train_sentence1_indices))]]\n",
    "# snli_val_concat_indices = [snli_val_sentence1_indices[i]+snli_val_sentence2_indices[i] for i in [*range(len(snli_val_sentence1_indices))]]\n",
    "\n",
    "# mnli_train_concat_indices = [mnli_train_sentence1_indices[i]+mnli_train_sentence2_indices[i] for i in [*range(len(mnli_train_sentence1_indices))]]\n",
    "# mnli_val_concat_indices = [mnli_val_sentence1_indices[i]+mnli_val_sentence2_indices[i] for i in [*range(len(mnli_val_sentence1_indices))]]\n",
    "\n",
    "# ## GENRES\n",
    "\n",
    "# ## telephone\n",
    "# mnli_train_tel_concat_indices = [mnli_train_s1_tel_ix[i]+mnli_train_s2_tel_ix[i] for i in [*range(len(mnli_train_s1_tel_ix))]]\n",
    "# mnli_val_tel_concat_indices = [mnli_val_s1_tel_ix[i]+mnli_val_s2_tel_ix[i] for i in [*range(len(mnli_val_s1_tel_ix))]]\n",
    "# ## slate\n",
    "# mnli_train_slate_concat_indices = [mnli_train_s1_slate_ix[i]+mnli_train_s2_slate_ix[i] for i in [*range(len(mnli_train_s2_slate_ix))]]\n",
    "# mnli_val_slate_concat_indices = [mnli_val_s1_slate_ix[i]+mnli_val_s2_slate_ix[i] for i in [*range(len(mnli_val_s2_slate_ix))]]\n",
    "# ## travel\n",
    "# mnli_train_travel_concat_indices = [mnli_train_s1_travel_ix[i]+mnli_train_s2_travel_ix[i] for i in [*range(len(mnli_train_s2_travel_ix))]]\n",
    "# mnli_val_travel_concat_indices = [mnli_val_s1_travel_ix[i]+mnli_val_s2_travel_ix[i] for i in [*range(len(mnli_val_s2_travel_ix))]]\n",
    "# ## gov\n",
    "# mnli_train_gov_concat_indices = [mnli_train_s1_gov_ix[i]+mnli_train_s2_gov_ix[i] for i in [*range(len(mnli_train_s2_gov_ix))]]\n",
    "# mnli_val_gov_concat_indices = [mnli_val_s1_gov_ix[i]+mnli_val_s2_gov_ix[i] for i in [*range(len(mnli_val_s2_gov_ix))]]\n",
    "# ## fiction\n",
    "# mnli_train_fiction_concat_indices = [mnli_train_s1_fiction_ix[i]+mnli_train_s2_fiction_ix[i] for i in [*range(len(mnli_train_s2_fiction_ix))]]\n",
    "# mnli_val_fiction_concat_indices = [mnli_val_s1_fiction_ix[i]+mnli_val_s2_fiction_ix[i] for i in [*range(len(mnli_val_s2_fiction_ix))]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting training and validation set __labels__ (targets) for both datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## SNLI\n",
    "# snli_train_labels = np.array(snli_train[\"label_num\"])\n",
    "# snli_val_labels = np.array(snli_val[\"label_num\"])\n",
    "\n",
    "# ## MNLI\n",
    "# mnli_train_labels = np.array(mnli_train[\"label_num\"])\n",
    "# mnli_val_labels = np.array(mnli_val[\"label_num\"])\n",
    "\n",
    "# ## GENRES\n",
    "\n",
    "# ## telephone\n",
    "# mnli_train_tel_labels = np.array(mnli_train_telephone[\"label_num\"])\n",
    "# mnli_val_tel_labels = np.array(mnli_val_telephone[\"label_num\"])\n",
    "# ## slate\n",
    "# mnli_train_slate_labels = np.array(mnli_train_slate[\"label_num\"])\n",
    "# mnli_val_slate_labels = np.array(mnli_val_slate[\"label_num\"])\n",
    "# ## travel\n",
    "# mnli_train_travel_labels = np.array(mnli_train_travel[\"label_num\"])\n",
    "# mnli_val_travel_labels = np.array(mnli_val_travel[\"label_num\"])\n",
    "# ## gov\n",
    "# mnli_train_gov_labels = np.array(mnli_train_government[\"label_num\"])\n",
    "# mnli_val_gov_labels = np.array(mnli_val_government[\"label_num\"])\n",
    "# ## fiction\n",
    "# mnli_train_fiction_labels = np.array(mnli_train_fiction[\"label_num\"])\n",
    "# mnli_val_fiction_labels = np.array(mnli_val_fiction[\"label_num\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get pretrained word embeddings from the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code taken from lab3\n",
    "\n",
    "## SNLI\n",
    "MAX_SENTENCE_LENGTH = 200\n",
    "snli_train_targets = snli_train_labels\n",
    "snli_val_targets = snli_val_labels\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SNLI_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of newsgroup tokens \n",
    "        @param target_list: list of newsgroup targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx), label]\n",
    "\n",
    "def snli_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "#         data_list.append(datum[0])\n",
    "        \n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "        \n",
    "    return [torch.from_numpy(np.array(data_list)), \n",
    "            torch.LongTensor(length_list), \n",
    "            torch.LongTensor(label_list)]\n",
    "\n",
    "# create pytorch dataloader\n",
    "\n",
    "# since I'm loading the sentences separately, I set shulle to False \n",
    "\n",
    "BATCH_SIZE = 32\n",
    "snli_train_dataset_s1 = SNLI_Dataset(snli_train_sentence1_indices,snli_train_labels)\n",
    "snli_train_dataset_s2 = SNLI_Dataset(snli_train_sentence2_indices,snli_train_labels)\n",
    "snli_train_loader_s1 = torch.utils.data.DataLoader(dataset=snli_train_dataset_s1,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=snli_func,\n",
    "                                               shuffle=False)\n",
    "snli_train_loader_s2 = torch.utils.data.DataLoader(dataset=snli_train_dataset_s2,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=snli_func,\n",
    "                                               shuffle=False)\n",
    "\n",
    "snli_val_dataset_s1 = SNLI_Dataset(snli_val_sentence1_indices, snli_val_labels)\n",
    "snli_val_dataset_s2 = SNLI_Dataset(snli_val_sentence2_indices, snli_val_labels)\n",
    "snli_val_loader_s1 = torch.utils.data.DataLoader(dataset=snli_val_dataset_s1,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             collate_fn=snli_func,\n",
    "                                             shuffle=False)\n",
    "snli_val_loader_s2 = torch.utils.data.DataLoader(dataset=snli_val_dataset_s2,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             collate_fn=snli_func,\n",
    "                                             shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will load two strings separately, and get the hidden representations as they're output from the encoder - again separately, then interact them to get the softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "## code taken from lab3\n",
    "## mnli\n",
    "MAX_SENTENCE_LENGTH = 200\n",
    "mnli_train_targets = mnli_train_labels\n",
    "mnli_val_targets = mnli_val_labels\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MNLI_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of newsgroup tokens \n",
    "        @param target_list: list of newsgroup targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx), label]\n",
    "\n",
    "def mnli_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "        \n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "            \n",
    "        data_list.append(padded_vec)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return [torch.from_numpy(np.array(data_list)), \n",
    "            torch.LongTensor(length_list), \n",
    "            torch.LongTensor(label_list)]\n",
    "\n",
    "# create pytorch dataloader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "mnli_train_dataset_s1 = MNLI_Dataset(mnli_train_sentence1_indices,mnli_train_labels)\n",
    "mnli_train_loader_s1 = torch.utils.data.DataLoader(dataset=mnli_train_dataset_s1,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=mnli_func,\n",
    "                                               shuffle=False)\n",
    "mnli_train_dataset_s2 = MNLI_Dataset(mnli_train_sentence2_indices,mnli_train_labels)\n",
    "mnli_train_loader_s2 = torch.utils.data.DataLoader(dataset=mnli_train_dataset_s2,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=mnli_func,\n",
    "                                               shuffle=False)\n",
    "\n",
    "\n",
    "mnli_val_dataset_s1 = MNLI_Dataset(mnli_val_sentence1_indices, mnli_val_labels)\n",
    "mnli_val_loader_s1 = torch.utils.data.DataLoader(dataset=mnli_val_dataset_s1,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             collate_fn=mnli_func,\n",
    "                                             shuffle=False)\n",
    "\n",
    "mnli_val_dataset_s2 = MNLI_Dataset(mnli_val_sentence2_indices, mnli_val_labels)\n",
    "mnli_val_loader_s2 = torch.utils.data.DataLoader(dataset=mnli_val_dataset_s2,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             collate_fn=mnli_func,\n",
    "                                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"and now that was in fifty one that 's forty years ago that it was already a problem so it 's now uh\""
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\" \").join([id2token_wiki[x] for x in [*mnli_train_dataset_s1][0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It was already a problem forty years ago but now it 's ten times worse !\""
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\" \").join([id2token_wiki[x] for x in [*mnli_train_dataset_s2][0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[594502, 705939, 794698,  ...,      0,      0,      0],\n",
       "         [ 99013, 744841, 733398,  ...,      0,      0,      0],\n",
       "         [324117, 802154, 906941,  ...,      0,      0,      0],\n",
       "         ...,\n",
       "         [181652, 784743, 949295,  ...,      0,      0,      0],\n",
       "         [336210, 793523, 792755,  ...,      0,      0,      0],\n",
       "         [428010, 904530, 802154,  ...,      0,      0,      0]]),\n",
       " tensor([ 9, 11, 13,  5,  8,  6, 27,  9, 10,  8,  6,  7, 13, 12,  6,  7,  9, 15,\n",
       "         13, 15, 11, 10,  6, 22, 13, 13, 11, 11,  5,  7,  8,  7]),\n",
       " tensor([[1, 0, 0],\n",
       "         [0, 1, 0],\n",
       "         [1, 0, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 1, 0],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 1],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [0, 1, 0],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [1, 0, 0],\n",
       "         [0, 1, 0],\n",
       "         [0, 1, 0],\n",
       "         [0, 1, 0],\n",
       "         [0, 1, 0],\n",
       "         [1, 0, 0],\n",
       "         [0, 0, 1],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [0, 1, 0]])]"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*mnli_train_loader_s2][29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Model\n",
    "\n",
    "The model is trained on SNLI training set. The best model is chosen using SNLI validation set, then the best model is evaluated on each genre in MultiNLI validation set. \n",
    "\n",
    "We will use an encoder (either a CNN or an RNN) to map each string of text (hypothesis and premise) to a fixed-dimension vector representation. \n",
    "\n",
    "- We will interact the two hidden representations and output a __3-class softmax__. \n",
    "\n",
    "- To keep things simple, we will simply __concatenate__ the two representations, and feed them through a network of __2 fully-connected layers__. \n",
    "\n",
    "- For the encoder, we want the following:\n",
    "\n",
    "### Part 2.1: CNN\n",
    "For the CNN, \n",
    "- A 2-layer 1-D convolutional network with ReLU activations \n",
    "- A max-pool at the end to compress the hidden representation into a single vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify to accept hard coded arguments\n",
    "# batch_size = 8\n",
    "# batch_size = 16\n",
    "epochs = 20\n",
    "no_cuda = False\n",
    "log_interval = 1\n",
    "\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "# cuda = False\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "# kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # FloatTensor containing pretrained weights\n",
    "# >> weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])\n",
    "# >> embedding = nn.Embedding.from_pretrained(weight)\n",
    "# >> # Get embeddings for index 1\n",
    "# >> input = torch.LongTensor([1])\n",
    "# >> embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_train_length = max([snli_train_dataset_s1[x][1] for x in range(len(snli_train_dataset_s1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max([snli_train_dataset_s2[x][1] for x in range(len(snli_train_dataset_s2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val_length = max([snli_val_dataset_s1[x][1] for x in range(len(snli_val_dataset_s1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max([snli_val_dataset_s2[x][1] for x in range(len(snli_val_dataset_s2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = [*snli_train_dataset]\n",
    "\n",
    "## init hidden or forward?\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,emb_size,\n",
    "                 hidden_size,\n",
    "                 num_classes,\n",
    "                 vocab_size,\n",
    "                 kernel_size,\n",
    "                 padding,\n",
    "                 stride,\n",
    "                 percent_dropout):\n",
    "\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.emb_size = emb_size\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.hidden_size = hidden_size\n",
    "        self.stride = stride\n",
    "\n",
    "        ## use pretrained wiki embeddings\n",
    "        wiki_embed_table = torch.tensor(table_lookup)\n",
    "        embedding = nn.Embedding.from_pretrained(wiki_embed_table)\n",
    "        self.embedding = embedding\n",
    "        \n",
    "        ## 2 1d convolutional layers\n",
    "        ## conv1\n",
    "        self.conv1 = nn.Conv1d(emb_size, hidden_size,\n",
    "                               kernel_size=self.kernel_size, \n",
    "                               padding=self.padding)\n",
    "        ## conv2\n",
    "        self.conv2 = nn.Conv1d(hidden_size, hidden_size,\n",
    "                               kernel_size=self.kernel_size, \n",
    "                               padding=self.padding)\n",
    "        \n",
    "        ## ReLU activations\n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        self.ReLU2 = nn.ReLU()\n",
    "        \n",
    "        ## Maxpool\n",
    "#         self.maxpool = torch.max(kernel_size=self.kernel_size,\n",
    "#                                             stride=self.stride,\n",
    "#                                             return_indices = True,\n",
    "#                                    )\n",
    "        \n",
    "        ## dropout\n",
    "        self.dropout = nn.Dropout(percent_dropout)\n",
    "        ## Fully Connected Layers for Concatenated \n",
    "        ## Hidden Representations\n",
    "        hidden_out = int(1+(hidden_size-self.kernel_size + 2*self.padding)/self.stride)\n",
    "        print (\"hidden out - \" +str(hidden_out))\n",
    "#         self.fc1 = nn.Linear(hidden_out, hidden_size)\n",
    "        self.fc1 = nn.Linear(hidden_out*2, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 3)\n",
    "        \n",
    "\n",
    "    def forward(self, x1, x2, lengths1, lengths2):\n",
    "        batch_size_1, seq_len_1 = x1.size()\n",
    "        batch_size_2, seq_len_2 = x2.size()\n",
    "\n",
    "        ## initialize batch embeddings for sentence 1\n",
    "        embeds_1 = []\n",
    "        embeds_2 = []\n",
    "        ## get embeddings for each sentence couple in batch\n",
    "        ## exclude zero-pads at the end, if you don't slice by length \n",
    "        ## the model will get table_lookup[0] for 0-pads\n",
    "        MAX_SENTENCE_LENGTH = max_train_length\n",
    "        \n",
    "        for arr in [*range(len(x1))]: \n",
    "            input = torch.LongTensor(x1[arr][:int(lengths1[arr])].cpu().numpy())\n",
    "            embed = self.embedding(input)\n",
    "            ## pad again\n",
    "            length_to_pad = MAX_SENTENCE_LENGTH - embed.size()[0]\n",
    "            embed = np.vstack((embed.cpu().numpy(),np.zeros((length_to_pad,300))))\n",
    "            embeds_1.append(embed)\n",
    "            \n",
    "        embeds_1 = torch.FloatTensor(embeds_1)\n",
    "            \n",
    "        for arr in [*range(len(x2))]: \n",
    "            input = torch.LongTensor(x2[arr][:int(lengths2[arr])].cpu().numpy())\n",
    "            embed = self.embedding(input)\n",
    "            ## pad again\n",
    "            length_to_pad = MAX_SENTENCE_LENGTH - embed.size()[0]\n",
    "            embed = np.vstack((embed.cpu().numpy(),np.zeros((length_to_pad,300))))\n",
    "            embeds_2.append(embed)\n",
    "\n",
    "        embeds_2 = torch.FloatTensor(embeds_2)\n",
    "\n",
    "        ## FIRST 1D CONVOLUTION\n",
    "        ## sentence 1 - conv1\n",
    "        s1_conv1 = self.conv1(torch.transpose(embeds_1, 1, 2)).transpose(1,2)\n",
    "        ## sentence 2 - conv 1\n",
    "        s2_conv1 = self.conv1(torch.transpose(embeds_2, 1, 2)).transpose(1,2)\n",
    "\n",
    "        ## FIRST RELU\n",
    "        ## sentence 1 - ReLU1\n",
    "        s1_ReLU1 = self.ReLU1(s1_conv1)\n",
    "#         s1_ReLU1 = self.ReLU1(s1_conv1.contiguous().view(-1, s1_conv1.size(-1))).view(BATCH_SIZE, seq_len_1, s1_conv1.size(-1))\n",
    "        ## sentence 2 - ReLU1\n",
    "        s2_ReLU1 = self.ReLU1(s2_conv1)\n",
    "#         s2_ReLU1 = self.ReLU1(s2_conv1.contiguous().view(-1, s2_conv1.size(-1))).view(BATCH_SIZE, seq_len_2, s2_conv1.size(-1))\n",
    "\n",
    "        ## SECOND 1D CONVOLUTION\n",
    "        ## sentence 1 - conv2\n",
    "        s1_conv2 = self.conv2(s1_ReLU1.transpose(1,2)).transpose(1,2)\n",
    "        ## sentence 2 - conv2\n",
    "        s2_conv2 = self.conv2(s2_ReLU1.transpose(1,2)).transpose(1,2)\n",
    "        \n",
    "        ## SECOND RELU\n",
    "        ## sentence 1 - ReLU2\n",
    "        s1_ReLU2 = self.ReLU2(s1_conv2)\n",
    "#         s1_ReLU2 = self.ReLU2(s1_conv2.contiguous().view(-1, s1_conv2.size(-1))).view(BATCH_SIZE, seq_len_1, s1_conv2.size(-1))\n",
    "        ## sentence 2 - ReLU2\n",
    "        s2_ReLU2 = self.ReLU2(s2_conv2)\n",
    "#         s2_ReLU2 = self.ReLU2(s2_conv2.contiguous().view(-1, s2_conv2.size(-1))).view(BATCH_SIZE, seq_len_2, s2_conv2.size(-1))\n",
    "#         print (\"s1_ReLU2 shape = \"+ str(s1_ReLU2.size()))\n",
    "        ## MAX-POOL - dropout\n",
    "        s1_hidden = torch.max(self.dropout(s1_ReLU2),1)\n",
    "        s2_hidden = torch.max(self.dropout(s2_ReLU2),1)\n",
    "\n",
    "        ## CONCATENATION\n",
    "        hidden = torch.cat((s1_hidden[0],s2_hidden[0]),1)\n",
    "#         hidden = torch.cat((s1_hidden[0],s2_hidden[0]),0)\n",
    "#         print (\"hidden = \"+str(hidden))\n",
    "#         print (\"hidden_shape = \"+str(hidden.size()))\n",
    "        ## FC LAYERS\n",
    "        hidden = self.fc1(hidden)\n",
    "        x = F.dropout(hidden, training=self.training)\n",
    "        hidden = self.fc2(hidden)\n",
    "\n",
    "        ## SOFTMAX\n",
    "        out = F.softmax(hidden)\n",
    "#         print (\"out = \"+str(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try Elementwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_embed_table = torch.Tensor(table_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden out - 60\n"
     ]
    }
   ],
   "source": [
    "model = CNN(emb_size=300, \n",
    "            hidden_size=60,\n",
    "            num_classes=3, \n",
    "            vocab_size=wiki_embed_table.size()[0],\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            stride=1,\n",
    "            percent_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.load(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden out - 60\n"
     ]
    }
   ],
   "source": [
    "the_model = CNN(emb_size=300, \n",
    "            hidden_size=60,\n",
    "            num_classes=3, \n",
    "            vocab_size=wiki_embed_table.size()[0],\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            stride=1,\n",
    "            percent_dropout=0.1)\n",
    "the_model.load_state_dict(torch.load(\"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 10 # number epoch to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [*enumerate(zip(snli_train_loader_s1,snli_train_loader_s2))][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 20\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    ## initialize loss hist\n",
    "    loss_history = []\n",
    "    for batch_idx, ([data_s1, lengths_s1, labels], \n",
    "    [data_s2, lengths_s2, labels]) in enumerate(zip(snli_train_loader_s1,\n",
    "                                                 snli_train_loader_s2)):\n",
    "        \n",
    "        data_s1 = data_s1\n",
    "        data_s2 = data_s2\n",
    "#         print(\"Data transfer to device completed.\")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_s1,data_s2,lengths_s1,lengths_s2)\n",
    "#         print (\"output = \"+str(output))\n",
    "        loss = criterion(output, labels)\n",
    "#         print (\"loss = \"+str(loss))\n",
    "        loss.backward()\n",
    "        \n",
    "        loss_history.append(loss.item())\n",
    "        \n",
    "        optimizer.step()\n",
    "        # if batch_idx % args.log_interval == 0:\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.12f}'.format(\n",
    "                epoch, batch_idx * len(data_s1), len(snli_train_loader_s1.dataset),\n",
    "                100. * batch_idx / len(snli_train_loader_s1),\n",
    "                loss.item() / len(data_s1)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.12f}'.format(\n",
    "          epoch, train_loss / len(snli_train_loader_s1.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for epoch in range(1, epochs + 1):\n",
    "#     print(\"Epoch = \" + str(epoch) + \" / \" + str(epochs))\n",
    "\n",
    "#     train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adc563/pytorch-cpu/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:135: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2acd0a92bdd8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = tensor(0.7628, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "def test_model(loader1, loader2, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for batch_idx, ([data_s1, lengths_s1, labels], \n",
    "    [data_s2, lengths_s2, labels]) in enumerate(zip(loader1,\n",
    "                                                 loader2)):\n",
    "        \n",
    "        outputs = model(data_s1, data_s2, lengths_s1, lengths_s2)\n",
    "#         print (\"outputs = \"+str(outputs))\n",
    "        predicted = outputs\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "        print (\"correct? = \"+str(correct))\n",
    "    return (100 * correct / total)\n",
    "\n",
    "total_step = len(snli_train_loader_s1)\n",
    "num_epochs = 10\n",
    "loss_hist = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, ([data_s1, lengths_s1, labels], \n",
    "    [data_s2, lengths_s2, labels]) in enumerate(zip(snli_train_loader_s1,\n",
    "                                                 snli_train_loader_s2)):\n",
    "        \n",
    "        the_model.train()\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(data_s1,data_s2,lengths_s1,lengths_s2)\n",
    "#         print (\"outputs = \"+str(outputs))\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        if batch_idx % 80 == 0:\n",
    "            loss_hist.append(loss)\n",
    "            plt.figure(figsize=(20,10))\n",
    "            plt.plot(loss_hist,color=\"b\",linewidth=3,alpha=0.6,marker=\"o\")\n",
    "            plt.rcParams[\"font.size\"] = 16\n",
    "            plt.title(\"Training Loss\")\n",
    "            plt.xlabel(\"Iterations\")\n",
    "            plt.ylabel(\"Cross Entropy\")\n",
    "            plt.show()\n",
    "            print (\"loss = \"+str(loss))\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # validate every 100 iterations\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            # validate\n",
    "            val_acc = test_model(snli_val_loader_s1,snli_val_loader_s2, model)\n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format(\n",
    "                       epoch+1, num_epochs, i+1, len(snli_train_loader_s1), val_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Search\n",
    "\n",
    "The hyperparameters included in the hyperparameter search space are;\n",
    "\n",
    "- The size of the hidden dimension of the CNN,\n",
    "- The kernel size of the CNN,\n",
    "- Experiment with different ways of interacting the two encoded sentences (concatenation, element-wise multiplication, outer multiplication etc)\n",
    "- Regularization (e.g. weight decay, dropout).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2 RNN\n",
    "For the RNN, a single-layer, bi-directional GRU will suffice. We can take the last hidden state as the encoder output. (In the case of bi-directional, the last of each direction, although PyTorch takes care of this.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, num_layers, num_classes, vocab_size):\n",
    "        # RNN Accepts the following hyperparams:\n",
    "        # emb_size: Embedding Size\n",
    "        # hidden_size: Hidden Size of layer in RNN\n",
    "        # num_layers: number of layers in RNN\n",
    "        # num_classes: number of output classes\n",
    "        # vocab_size: vocabulary size\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "        ## use pretrained wiki embeddings\n",
    "        wiki_embed_table = torch.tensor(table_lookup)\n",
    "        embedding = nn.Embedding.from_pretrained(wiki_embed_table)\n",
    "        self.embedding = embedding\n",
    "        ## the following line\n",
    "        ## responsible for creating the rnn in pytorch\n",
    "        self.rnn = nn.RNN(emb_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Function initializes the activation of recurrent neural net at timestep 0\n",
    "        # Needs to be in format (num_layers, batch_size, hidden_size)\n",
    "        hidden = torch.randn(self.num_layers, batch_size, self.hidden_size)\n",
    "\n",
    "        return hidden\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # reset hidden state\n",
    "\n",
    "        batch_size, seq_len = x.size()\n",
    "\n",
    "        self.hidden = self.init_hidden(batch_size)\n",
    "        \n",
    "        ## no need to pad here of course\n",
    "\n",
    "        # get embedding of characters\n",
    "        embed = self.embedding(x)\n",
    "        ## pack padded sequence - transforms pytorch tensor into padded sequence\n",
    "        ## keep in mind that pytorch expects your embedding size to be in descending order\n",
    "        embed = torch.nn.utils.rnn.pack_padded_sequence(embed, lengths.numpy(), batch_first=True)\n",
    "        # fprop though RNN - pass embedding to the RNN\n",
    "        rnn_out, self.hidden = self.rnn(embed, self.hidden)\n",
    "        # undo packing\n",
    "        rnn_out, _ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out, batch_first=True)\n",
    "        # sum hidden activations of RNN across time\n",
    "        rnn_out = torch.sum(rnn_out, dim=1)\n",
    "\n",
    "        logits = self.linear(rnn_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, lengths_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, lengths_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n",
    "model = RNN(emb_size=100, hidden_size=200, num_layers=2, num_classes=5, vocab_size=len(id2char))\n",
    "\n",
    "learning_rate = 3e-4\n",
    "num_epochs = 10 # number epoch to train\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(data, lengths)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # validate every 100 iterations\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            # validate\n",
    "            val_acc = test_model(val_loader, model)\n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format(\n",
    "                       epoch+1, num_epochs, i+1, len(train_loader), val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Search\n",
    "\n",
    "The hyperparameters included in the hyperparameter search space are;\n",
    "\n",
    "- The size of the hidden dimension of the CNN and RNN,\n",
    "- Experiment with different ways of interacting the two encoded sentences (concatenation, element-wise multiplication, outer multiplication etc)\n",
    "- Regularization (e.g. weight decay, dropout)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
